AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: False
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('object365_dt_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: False
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: swin_tiny_patch4_window7_224.pth
OUTPUT_DIR: OUTPUT
PATHS_CATALOG: /data1/yenanfei/git/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 64
  LANG_LR: 1e-05
  MAX_EPOCH: 30
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: None
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: 
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 64
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 4
args.opts ['MODEL.WEIGHT', 'MODEL/glip_a_tiny_o365.pth', 'SOLVER.USE_AMP', 'True', 'TEST.DURING_TRAINING', 'True', 'TEST.IMS_PER_BATCH', '4', 'SOLVER.IMS_PER_BATCH', '4', 'SOLVER.WEIGHT_DECAY', '0.05', 'TEST.EVAL_TASK', 'detection', 'DATASETS.TRAIN_DATASETNAME_SUFFIX', '_grounding', 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '2', 'MODEL.DYHEAD.USE_CHECKPOINT', 'True', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.TEST_WITH_INFERENCE', 'True', 'SOLVER.USE_AUTOSTEP', 'True', 'DATASETS.USE_OVERRIDE_CATEGORY', 'True', 'SOLVER.SEED', '10', 'DATASETS.SHUFFLE_SEED', '3', 'DATASETS.USE_CAPTION_PROMPT', 'True', 'DATASETS.DISABLE_SHUFFLE', 'True', 'SOLVER.STEP_PATIENCE', '2', 'SOLVER.CHECKPOINT_PER_EPOCH', '1.0', 'SOLVER.AUTO_TERMINATE_PATIENCE', '4', 'SOLVER.MODEL_EMA', '0.0', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'full', 'DATALOADER.DISTRIBUTE_CHUNK_AMONG_NODE', 'False']
2023-05-11 09:00:57,222 maskrcnn_benchmark INFO: Using 4 GPUs
2023-05-11 09:00:57,222 maskrcnn_benchmark INFO: Namespace(config_file='configs/pretrain/glip_A_Swin_T_O365.yaml', custom_shot_and_epoch_and_general_copy='0_200_1', distributed=True, evaluate_only_best_on_test=True, ft_tasks='/data1/yenanfei/git/GLIP/configs/custom_dataset.yaml', keep_testing=False, local_rank=0, opts=['MODEL.WEIGHT', 'MODEL/glip_a_tiny_o365.pth', 'SOLVER.USE_AMP', 'True', 'TEST.DURING_TRAINING', 'True', 'TEST.IMS_PER_BATCH', '4', 'SOLVER.IMS_PER_BATCH', '4', 'SOLVER.WEIGHT_DECAY', '0.05', 'TEST.EVAL_TASK', 'detection', 'DATASETS.TRAIN_DATASETNAME_SUFFIX', '_grounding', 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '2', 'MODEL.DYHEAD.USE_CHECKPOINT', 'True', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.TEST_WITH_INFERENCE', 'True', 'SOLVER.USE_AUTOSTEP', 'True', 'DATASETS.USE_OVERRIDE_CATEGORY', 'True', 'SOLVER.SEED', '10', 'DATASETS.SHUFFLE_SEED', '3', 'DATASETS.USE_CAPTION_PROMPT', 'True', 'DATASETS.DISABLE_SHUFFLE', 'True', 'SOLVER.STEP_PATIENCE', '2', 'SOLVER.CHECKPOINT_PER_EPOCH', '1.0', 'SOLVER.AUTO_TERMINATE_PATIENCE', '4', 'SOLVER.MODEL_EMA', '0.0', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'full', 'DATALOADER.DISTRIBUTE_CHUNK_AMONG_NODE', 'False'], push_both_val_and_test=True, shuffle_seeds=None, skip_optimizer_resume=False, skip_test=True, skip_train=False, use_prepared_data=False)
2023-05-11 09:00:57,222 maskrcnn_benchmark INFO: Loaded configuration file configs/pretrain/glip_A_Swin_T_O365.yaml
2023-05-11 09:00:57,222 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedVLRCNN"
  WEIGHT: "swin_tiny_patch4_window7_224.pth"
  RPN_ONLY: True
  RPN_ARCHITECTURE: "VLDYHEAD"

  BACKBONE:
    CONV_BODY: "SWINT-FPN-RETINANET"
    OUT_CHANNELS: 256
    FREEZE_CONV_BODY_AT: -1

  LANGUAGE_BACKBONE:
    FREEZE: False
    MODEL_TYPE: "bert-base-uncased" # "roberta-base", "clip"
    MASK_SPECIAL: False

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    SCALES_PER_OCTAVE: 1

  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
    USE_GN: True
    USE_DYRELU: True
    USE_DFCONV: True
    USE_DYFUSE: True
    TOPK: 9 # topk for selecting candidate positive samples from each level
    SCORE_AGG: "MEAN"
    LOG_SCALE: 0.0

    FUSE_CONFIG:
      EARLY_FUSE_ON: False
      TYPE: "MHA-B"
      USE_CLASSIFICATION_LOSS: False
      USE_TOKEN_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      CONTRASTIVE_HIDDEN_DIM: 64
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_DOT_PRODUCT: True
           
    USE_CHECKPOINT: True

TEST:
  DURING_TRAINING: False
  IMS_PER_BATCH: 64

# use for grounding model
DATASETS:
  TRAIN: ("object365_dt_train", )
  TEST: ("coco_2017_val", )
  DISABLE_SHUFFLE: False
  ADD_DET_PROMPT: False
  RANDOM_SAMPLE_NEG: 85
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)

  SEPARATION_TOKENS: ". "

INPUT:
  PIXEL_MEAN: [ 103.530, 116.280, 123.675 ]
  PIXEL_STD: [ 57.375, 57.120, 58.395 ]
  MIN_SIZE_TRAIN: 800
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333

AUGMENT:
  MULT_MIN_SIZE_TRAIN: (480,560,640,720,800)

DATALOADER:
  SIZE_DIVISIBILITY: 32

SOLVER:
  OPTIMIZER: ADAMW
  BASE_LR: 0.0001
  LANG_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  STEPS: (0.67, 0.89)
  MAX_EPOCH: 30
  IMS_PER_BATCH: 64
  WARMUP_ITERS: 2000
  WARMUP_FACTOR: 0.001
  USE_AMP: True
  MODEL_EMA: 0.999
  FIND_UNUSED_PARAMETERS: False

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0
2023-05-11 09:00:57,223 maskrcnn_benchmark INFO: Running with config:
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: True
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 3
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('object365_dt_train',)
  TRAIN_DATASETNAME_SUFFIX: _grounding
  USE_CAPTION_PROMPT: True
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: True
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: 2
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: False
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: MODEL/glip_a_tiny_o365.pth
OUTPUT_DIR: OUTPUT
PATHS_CATALOG: /data1/yenanfei/git/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: 4
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: 1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 4
  LANG_LR: 1e-05
  MAX_EPOCH: 30
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.0
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 10
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 2
  TEST_WITH_INFERENCE: True
  TUNING_HIGHLEVEL_OVERRIDE: full
  USE_AMP: True
  USE_AUTOSTEP: True
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: True
  EVAL_TASK: detection
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 4
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 0
num_gpus: 4
2023-05-11 09:00:57,224 maskrcnn_benchmark INFO: Saving config into: OUTPUT/config.yml
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: False
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('object365_dt_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: False
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: swin_tiny_patch4_window7_224.pth
OUTPUT_DIR: OUTPUT
PATHS_CATALOG: /data1/yenanfei/git/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 64
  LANG_LR: 1e-05
  MAX_EPOCH: 30
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: None
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: 
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 64
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 2
num_gpus: 4
args.opts ['MODEL.WEIGHT', 'MODEL/glip_a_tiny_o365.pth', 'SOLVER.USE_AMP', 'True', 'TEST.DURING_TRAINING', 'True', 'TEST.IMS_PER_BATCH', '4', 'SOLVER.IMS_PER_BATCH', '4', 'SOLVER.WEIGHT_DECAY', '0.05', 'TEST.EVAL_TASK', 'detection', 'DATASETS.TRAIN_DATASETNAME_SUFFIX', '_grounding', 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '2', 'MODEL.DYHEAD.USE_CHECKPOINT', 'True', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.TEST_WITH_INFERENCE', 'True', 'SOLVER.USE_AUTOSTEP', 'True', 'DATASETS.USE_OVERRIDE_CATEGORY', 'True', 'SOLVER.SEED', '10', 'DATASETS.SHUFFLE_SEED', '3', 'DATASETS.USE_CAPTION_PROMPT', 'True', 'DATASETS.DISABLE_SHUFFLE', 'True', 'SOLVER.STEP_PATIENCE', '2', 'SOLVER.CHECKPOINT_PER_EPOCH', '1.0', 'SOLVER.AUTO_TERMINATE_PATIENCE', '4', 'SOLVER.MODEL_EMA', '0.0', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'full', 'DATALOADER.DISTRIBUTE_CHUNK_AMONG_NODE', 'False']
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: False
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('object365_dt_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: False
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: swin_tiny_patch4_window7_224.pth
OUTPUT_DIR: OUTPUT
PATHS_CATALOG: /data1/yenanfei/git/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 64
  LANG_LR: 1e-05
  MAX_EPOCH: 30
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: None
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: 
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 64
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 3
num_gpus: 4
args.opts ['MODEL.WEIGHT', 'MODEL/glip_a_tiny_o365.pth', 'SOLVER.USE_AMP', 'True', 'TEST.DURING_TRAINING', 'True', 'TEST.IMS_PER_BATCH', '4', 'SOLVER.IMS_PER_BATCH', '4', 'SOLVER.WEIGHT_DECAY', '0.05', 'TEST.EVAL_TASK', 'detection', 'DATASETS.TRAIN_DATASETNAME_SUFFIX', '_grounding', 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '2', 'MODEL.DYHEAD.USE_CHECKPOINT', 'True', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.TEST_WITH_INFERENCE', 'True', 'SOLVER.USE_AUTOSTEP', 'True', 'DATASETS.USE_OVERRIDE_CATEGORY', 'True', 'SOLVER.SEED', '10', 'DATASETS.SHUFFLE_SEED', '3', 'DATASETS.USE_CAPTION_PROMPT', 'True', 'DATASETS.DISABLE_SHUFFLE', 'True', 'SOLVER.STEP_PATIENCE', '2', 'SOLVER.CHECKPOINT_PER_EPOCH', '1.0', 'SOLVER.AUTO_TERMINATE_PATIENCE', '4', 'SOLVER.MODEL_EMA', '0.0', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'full', 'DATALOADER.DISTRIBUTE_CHUNK_AMONG_NODE', 'False']
AUGMENT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  CROP_MIN_IOUS: (0.1, 0.3, 0.5, 0.7, 0.9)
  CROP_MIN_SIZE: 0.3
  CROP_PROB: 0.5
  FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MULT_MIN_SIZE_TRAIN: (480, 560, 640, 720, 800)
  SATURATION: 0.0
  USE_RA: 0
  VERTICAL_FLIP_PROB_TRAIN: 0.0
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DISTRIBUTE_CHUNK_AMONG_NODE: False
  MIN_KPS_PER_IMS: 0
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
  USE_RANDOM_SEED: False
DATASETS:
  ADD_DET_PROMPT: False
  ADD_DET_PROMPT_ADVANCED: False
  ALTERNATIVE_TRAINING: False
  BING_INDEX_LIST: []
  BOX_THRESHOLD: 0.1
  CAPTION_CONF: 0.9
  CAPTION_FORMAT_VERSION: v1
  CAPTION_MIN_BOX: 1
  CAPTION_NMS: 0.9
  CAPTION_PROMPT: None
  CLASS_AGNOSTIC: False
  CLASS_CONCAT: False
  COCO_COPY: 1
  CONTROL_PROB: (0.0, 0.0, 0.5, 0.0)
  DISABLE_CLIP_TO_IMAGE: False
  DISABLE_SHUFFLE: False
  DIVER_BOX_FOR_VQA: False
  FEW_SHOT: 0
  FLICKR_COPY: 1
  FLICKR_GT_TYPE: separate
  FULL_QUESTION_PROB: 0.5
  FURTHER_SCREEN: False
  GENERAL_COPY: -1
  GENERAL_COPY_TEST: -1
  INFERENCE_CAPTION: False
  IN_COPY: 1
  LOCAL_DEBUG: False
  LVIS_COPY: 1
  LVIS_USE_NORMAL_AP: False
  MAX_BOX: -1
  MIXED_COPY: 1
  MULTISTAGE_TRAINING: False
  NEG_QUESTION_PROB: 0.8
  NO_MINUS_ONE_FOR_ONE_HOT: False
  NO_RANDOM_PACK_PROBABILITY: 0.0
  OBJECT365_COPY: 1
  OI_COPY: 1
  ONE_HOT: False
  OVERRIDE_CATEGORY: None
  PACK_RANDOM_CAPTION_NUMBER: 0
  POS_QUESTION_PROB: 0.6
  PREDEFINED_TEXT: None
  PROMPT_LIMIT_NEG: -1
  PROMPT_VERSION: 
  RANDOM_PACK_PROB: -1.0
  RANDOM_SAMPLE_NEG: 85
  REGISTER:
    
  REPLACE_CLEAN_LABEL: False
  SAFEGUARD_POSITIVE_CAPTION: True
  SAMPLE_NEGATIVE_FOR_GROUNDING_DATA: -1.0
  SAMPLE_RATIO: 0.0
  SEPARATION_TOKENS: . 
  SHUFFLE_SEED: 0
  SPECIAL_SAFEGUARD_FOR_COCO_GROUNDING: False
  SUPRESS_QUERY: None
  TEST: ('coco_2017_val',)
  TEST_DATASETNAME_SUFFIX: 
  TRAIN: ('object365_dt_train',)
  TRAIN_DATASETNAME_SUFFIX: 
  USE_CAPTION_PROMPT: False
  USE_COCO_FORMAT: False
  USE_CROWD: False
  USE_OD_AUG: False
  USE_OVERRIDE_CATEGORY: False
  USE_SUPRESS_QUERY: False
  VG_COPY: 1
GLIPKNOW:
  GPT3_NUM: 5
  KNOWLEDGE_FILE: 
  KNOWLEDGE_TYPE: 
  LAN_FEATURE_AGG_TYPE: first
  MAX_NUM_CLASSES_PER_BATCH_TRAIN: -1
  PARALLEL_LANGUAGE_INPUT: False
  WIKI_AND_GPT3: False
INPUT:
  FIX_RES: False
  FORMAT: 
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [57.375, 57.12, 58.395]
  TO_BGR255: True
MODEL:
  ATSS:
    CHANNELS: 128
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    NMS_TH: 0.6
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_BN: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_GN: False
    USE_SE: False
  BACKBONE:
    CONV_BODY: SWINT-FPN-RETINANET
    EFFICIENT_DET_BIFPN_VERSION: 0
    EFFICIENT_DET_COMPOUND: 0
    EFFICIENT_DET_START_FROM: 3
    FPN_LAYER: ()
    FREEZE: False
    FREEZE_CONV_BODY_AT: -1
    GROUP: 1
    LAYER_SEARCH:
      
    LAYER_SETUP: (3, 4, 6, 3)
    NORM_LEVEL: 3
    OUT_CHANNELS: 256
    OUT_FEATURES: ('stage2', 'stage3', 'stage4', 'stage5')
    RESET_BN: False
    USE_BN: False
    USE_CHECKPOINT: False
    USE_DFCONV: False
    USE_DYRELU: False
    USE_EN: False
    USE_GN: False
    USE_NSYNCBN: False
    USE_SE: False
    USE_SYNCBN: False
  BIFPN:
    NUM_REPEATS: 1
    USE_ATTENTION: True
  BOX_ON: True
  CLIP:
    CONTEXT_LENGTH: 256
    DROP_PATH: 0.0
    HEADS: 8
    LAYERS: 12
    TOKENIZER: clip
    VOCAB_SIZE: 49408
    WIDTH: 512
  DEBUG: False
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    CONV_FUNC: 
    COSINE_SCALE: -1.0
    FUSE_CONFIG:
      ADD_LINEAR_LAYER: False
      CLAMP_BERTATTN_MAX_FOR_OVERFLOW: True
      CLAMP_BERTATTN_MIN_FOR_UNDERFLOW: True
      CLAMP_DOT_PRODUCT: True
      CLAMP_MAX_FOR_OVERFLOW: True
      CLAMP_MIN_FOR_UNDERFLOW: True
      CONTRASTIVE_ALIGN_LOSS_WEIGHT: 1.0
      CONTRASTIVE_HIDDEN_DIM: 64
      DOT_PRODUCT_TOKEN_LOSS_WEIGHT: 1.0
      DO_LANG_PROJ_OUTSIDE_CHECKPOINT: False
      EARLY_FUSE_ON: False
      JOINT_EMB_DROPOUT: 0.1
      JOINT_EMB_SIZE: 256
      JOINT_MLP_LAYERS: 2
      JOINT_OUT_SIZE: 256
      MLM_LOSS: False
      MLM_LOSS_COEF: 1.0
      MLM_LOSS_FOR_ONLY_POSITIVES: True
      MLM_OBJ_FOR_ONLY_POSITIVE: False
      NO_MASK_FOR_GOLD: False
      NO_MASK_FOR_OD: False
      SEPARATE_BIDIRECTIONAL: False
      SHALLOW_CONTRASTIVE_HIDDEN_DIM: 64
      SHALLOW_CONTRASTIVE_LOSS_WEIGHT: 1.0
      SHALLOW_MAX_POSITIVE_ANCHORS: 100
      STABLE_SOFTMAX_2D: False
      TOKEN_ALPHA: 0.25
      TOKEN_GAMMA: 2.0
      TOKEN_LOSS_WEIGHT: 1.0
      TYPE: MHA-B
      USE_BACKBONE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_CLASSIFICATION_LOSS: False
      USE_CONTRASTIVE_ALIGN_LOSS: False
      USE_DOT_PRODUCT_TOKEN_LOSS: True
      USE_FUSED_FEATURES_DOT_PRODUCT: False
      USE_LAYER_SCALE: True
      USE_SHALLOW_CONTRASTIVE_LOSS: False
      USE_SHALLOW_ZERO_PADS: False
      USE_TOKEN_LOSS: False
    GROUPS: 1
    LOG_SCALE: 0.0
    NUM_CLASSES: 81
    NUM_CONVS: 6
    PRIOR_PROB: 0.01
    SCORE_AGG: MEAN
    SHALLOW_LOG_SCALE: 0.0
    TOPK: 9
    USE_CHECKPOINT: True
    USE_DFCONV: True
    USE_DYFUSE: True
    USE_DYRELU: True
    USE_GN: True
    USE_NSYNCBN: False
    USE_SYNCBN: False
  EVO_NORM:
    EPSILON: 1e-05
    NUM_GROUPS: 8
  FCOS:
    CENTERNESS_ON_REG: False
    CENTER_SAMPLING_RADIUS: 0.0
    DETECTIONS_PER_IMG: 100
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH: 0.05
    INFERENCE_TH_TRAIN: 0.0
    IOU_LOSS_TYPE: iou
    NMS_TH: 0.6
    NORM_REG_TARGETS: False
    NUM_CLASSES: 81
    NUM_CONVS: 4
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N: 1000
    PRE_NMS_TOP_N_TRAIN: 3000
    PRIOR_PROB: 0.01
    USE_BN: False
    USE_DFCONV: False
    USE_GN: False
    USE_GT_CENTER: False
  FOCAL:
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
  FPN:
    DROP_BLOCK: True
    DROP_PROB: 0.3
    DROP_SIZE: 3
    FREEZE: False
    RETURN_SWINT_FEATURE_BEFORE_FUSION: False
    USE_DYHEAD: False
    USE_DYRELU: False
    USE_GN: False
    USE_PAN: False
    USE_RELU: False
    USE_SPP: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 16
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    BIDIRECTIONAL: True
    CORPUS_PATH: 
    DROPOUT_P: 0.2
    FREEZE: False
    HIDDEN_SIZE: 512
    INPUT_DROPOUT_P: 0.5
    LANG_DIM: 768
    MASK_SPECIAL: False
    MAX_QUERY_LEN: 256
    MODEL_TYPE: bert-base-uncased
    N_LAYERS: 1
    PAD_MAX: True
    RNN_TYPE: lstm
    TOKENIZER_TYPE: bert-base-uncased
    UNUSED_TOKEN: 106
    USE_CHECKPOINT: False
    VARIABLE_LENGTH: True
    VOCAB_SIZE: 0
    WEIGHT: 
    WORD_EMBEDDING_SIZE: 512
    WORD_VEC_SIZE: 512
  LINEAR_PROB: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedVLRCNN
  MULTITASK:
    
  ONNX: False
  PRETRAIN_NAME: 
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    REVISION: resnet_light
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    USE_AVG_DOWN: False
    USE_STEM3X3: False
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
    WITH_SE: False
  RETINANET:
    DETECTIONS_PER_IMG: 100
    INFERENCE_TH: 0.05
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_ALIGNED: False
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    KEYPOINT_NAME: ()
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    HG_SCALE: 1
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SHIFT: (0.0, 0.0, 0.0, 0.0)
    ANCHOR_SIZES: (64, 128, 256, 512, 1024)
    ANCHOR_STRIDE: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (1.0,)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FORCE_BOXES: False
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    FREEZE: False
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    OCTAVE: 2.0
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RETURN_FUSED_FEATURES: False
    RPN_HEAD: SingleConvRPNHead
    SCALES_PER_OCTAVE: 1
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_RELATIVE_SIZE: False
  RPN_ARCHITECTURE: VLDYHEAD
  RPN_ONLY: True
  SPEC:
    
  SWINT:
    APE: False
    DEPTHS: (2, 2, 6, 2)
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    LAYER_SCALE: 0
    MLP_RATIO: 4
    NUM_HEADS: (3, 6, 12, 24)
    OUT_CHANNELS: (96, 192, 384, 768)
    OUT_NORM: True
    VERSION: v1
    WINDOW_SIZE: 7
  WEIGHT: swin_tiny_patch4_window7_224.pth
OUTPUT_DIR: OUTPUT
PATHS_CATALOG: /data1/yenanfei/git/GLIP/maskrcnn_benchmark/config/paths_catalog.py
SEARCH:
  CROSSOVER_NUM: 24
  MAX_EPOCH: 20
  MUTATION_NUM: 24
  MUTATION_PROB: 0.1
  POPULATION_NUM: 64
  SELECT_NUM: 20
SOLVER:
  AUTO_TERMINATE_PATIENCE: -1
  BACKBONE_BODY_LR_FACTOR: 1.0
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  CHECKPOINT_PER_EPOCH: -1.0
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  DATASET_LENGTH: -1
  DISABLE_OUTPUT_DISTRIBUTED: False
  FIND_UNUSED_PARAMETERS: False
  GAMMA: 0.1
  GRAD_CLIP: 0.0
  IMS_PER_BATCH: 64
  LANG_LR: 1e-05
  MAX_EPOCH: 30
  MAX_ITER: 40000
  MAX_NEG_PER_BATCH: 0.1
  MIN_LR: 1e-06
  MODEL_EMA: 0.999
  MOMENTUM: 0.9
  MULTI_MAX_EPOCH: ()
  MULTI_MAX_ITER: ()
  OPTIMIZER: ADAMW
  PROMPT_PROBING_LEVEL: -1.0
  SEED: 0
  STEPS: (0.67, 0.89)
  STEP_PATIENCE: 5
  TEST_WITH_INFERENCE: False
  TUNING_HIGHLEVEL_OVERRIDE: None
  USE_AMP: True
  USE_AUTOSTEP: False
  USE_COSINE: False
  USE_EMA_FOR_MONITOR: False
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM_FACTOR: 1.0
  WEIGHT_DECAY_SCHEDULE: False
  WEIGHT_DECAY_SCHEDULE_RATIO: 0.667
TENSORBOARD_EXP: OUTPUT
TEST:
  CHUNKED_EVALUATION: -1
  DURING_TRAINING: False
  EVAL_TASK: 
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  FLIP: True
  IMS_PER_BATCH: 64
  MAX_SIZE: 2500
  MDETR_STYLE_AGGREGATE_CLASS_NUM: -1
  NUM_CLASSES: 81
  PRE_NMS_TOP_N: 1000
  RANGES: ((96, 10000), (96, 10000), (64, 10000), (64, 10000), (64, 10000), (0, 10000), (0, 10000), (0, 256), (0, 256), (0, 192), (0, 192), (0, 96))
  SCALES: (400, 500, 600, 640, 700, 900, 1000, 1100, 1200, 1300, 1400, 1800)
  SELECT_CLASSES: ()
  SPECIAL_NMS: none
  SUBSET: -1
  TH: 0.6
  USE_MULTISCALE: False
local_rank: 1
num_gpus: 4
args.opts ['MODEL.WEIGHT', 'MODEL/glip_a_tiny_o365.pth', 'SOLVER.USE_AMP', 'True', 'TEST.DURING_TRAINING', 'True', 'TEST.IMS_PER_BATCH', '4', 'SOLVER.IMS_PER_BATCH', '4', 'SOLVER.WEIGHT_DECAY', '0.05', 'TEST.EVAL_TASK', 'detection', 'DATASETS.TRAIN_DATASETNAME_SUFFIX', '_grounding', 'MODEL.BACKBONE.FREEZE_CONV_BODY_AT', '2', 'MODEL.DYHEAD.USE_CHECKPOINT', 'True', 'SOLVER.FIND_UNUSED_PARAMETERS', 'False', 'SOLVER.TEST_WITH_INFERENCE', 'True', 'SOLVER.USE_AUTOSTEP', 'True', 'DATASETS.USE_OVERRIDE_CATEGORY', 'True', 'SOLVER.SEED', '10', 'DATASETS.SHUFFLE_SEED', '3', 'DATASETS.USE_CAPTION_PROMPT', 'True', 'DATASETS.DISABLE_SHUFFLE', 'True', 'SOLVER.STEP_PATIENCE', '2', 'SOLVER.CHECKPOINT_PER_EPOCH', '1.0', 'SOLVER.AUTO_TERMINATE_PATIENCE', '4', 'SOLVER.MODEL_EMA', '0.0', 'SOLVER.TUNING_HIGHLEVEL_OVERRIDE', 'full', 'DATALOADER.DISTRIBUTE_CHUNK_AMONG_NODE', 'False']
Saving config into: OUTPUT/ft_task_1/config.yml
The combined datasets are: ('train',).
Saving config into: OUTPUT/ft_task_1/config.yml
The combined datasets are: ('train',).
Saving config into: OUTPUT/ft_task_1/config.yml
The combined datasets are: ('train',).
2023-05-11 09:00:57,275 maskrcnn_benchmark INFO: Loaded fine-tune configuration file /data1/yenanfei/git/GLIP/configs/custom_dataset.yaml
2023-05-11 09:00:57,275 maskrcnn_benchmark INFO: 
DATALOADER:
  ASPECT_RATIO_GROUPING: false
  SIZE_DIVISIBILITY: 32
DATASETS:
  GENERAL_COPY: 16
  OVERRIDE_CATEGORY: '[
        {
            "name": "number/scale",
            "supercategory": "number/scale",
            "id": 1
        },
        {
            "name": "box",
            "supercategory": "box",
            "id": 2
        },
        {
            "name": "pointer",
            "supercategory": "pointer",
            "id": 3
        }
    ]'
  # PREDEFINED_TEXT: odinw/pothole/category_description.json
  REGISTER:
    test:
      ann_file: /data1/yenanfei/git/datasets/clock/val/val.json
      img_dir: /data1/yenanfei/git/datasets/clock/val/images
    train:
      ann_file: /data1/yenanfei/git/datasets/clock/train/train.json
      img_dir: /data1/yenanfei/git/datasets/clock/train/images
    val:
      ann_file: /data1/yenanfei/git/datasets/clock/val/val.json
      img_dir: /data1/yenanfei/git/datasets/clock/val/images
  TEST: ("val",)
  TRAIN: ("train",)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: 800
MODEL:
  ATSS:
    NUM_CLASSES: 3
  DYHEAD:
    NUM_CLASSES: 3
  FCOS:
    NUM_CLASSES: 3
  ROI_BOX_HEAD:
    NUM_CLASSES: 3
SOLVER:
  CHECKPOINT_PERIOD: 100
  MAX_EPOCH: 12
  WARMUP_ITERS: 0
TEST:
  IMS_PER_BATCH: 8

Saving config into: OUTPUT/ft_task_1/config.yml
2023-05-11 09:00:57,316 maskrcnn_benchmark INFO: Training /data1/yenanfei/git/GLIP/configs/custom_dataset.yaml
The combined datasets are: ('train',).
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.11s)
creating index...
index created!
train_grounding has the 101 data points CocoGrounding
Number of iterations are 5050
The combined datasets are: ('val',).
Done (t=0.10s)
creating index...
index created!
train_grounding has the 101 data points CocoGrounding
Number of iterations are 5050
The combined datasets are: ('val',).
Done (t=0.09s)
creating index...
index created!
train_grounding has the 101 data points CocoGrounding
Number of iterations are 5050
The combined datasets are: ('val',).
loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
Override category:  [{'name': 'number/scale', 'supercategory': 'number/scale', 'id': 1}, {'name': 'box', 'supercategory': 'box', 'id': 2}, {'name': 'pointer', 'supercategory': 'pointer', 'id': 3}]
val has the 20 data points COCODataset
VISION BACKBONE USE GRADIENT CHECKPOINTING:  False
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
Override category:  [{'name': 'number/scale', 'supercategory': 'number/scale', 'id': 1}, {'name': 'box', 'supercategory': 'box', 'id': 2}, {'name': 'pointer', 'supercategory': 'pointer', 'id': 3}]
val has the 20 data points COCODataset
VISION BACKBONE USE GRADIENT CHECKPOINTING:  False
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
Override category:  [{'name': 'number/scale', 'supercategory': 'number/scale', 'id': 1}, {'name': 'box', 'supercategory': 'box', 'id': 2}, {'name': 'pointer', 'supercategory': 'pointer', 'id': 3}]
val has the 20 data points COCODataset
VISION BACKBONE USE GRADIENT CHECKPOINTING:  False
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
train_grounding has the 101 data points CocoGrounding
Number of iterations are 5050
The combined datasets are: ('val',).
LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False
LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
Override category:  [{'name': 'number/scale', 'supercategory': 'number/scale', 'id': 1}, {'name': 'box', 'supercategory': 'box', 'id': 2}, {'name': 'pointer', 'supercategory': 'pointer', 'id': 3}]
val has the 20 data points COCODataset
VISION BACKBONE USE GRADIENT CHECKPOINTING:  False
LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False
LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False
GeneralizedVLRCNN(
  (backbone): Sequential(
    (body): SwinTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=96, out_features=288, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=96, out_features=96, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): Identity()
              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=96, out_features=384, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=384, out_features=96, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=96, out_features=288, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=96, out_features=96, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.018)
              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=96, out_features=384, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=384, out_features=96, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=384, out_features=192, bias=False)
            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=192, out_features=576, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=192, out_features=192, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.036)
              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=192, out_features=768, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=768, out_features=192, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=192, out_features=576, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=192, out_features=192, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.055)
              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=192, out_features=768, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=768, out_features=192, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=768, out_features=384, bias=False)
            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.073)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.091)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.109)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.127)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.145)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=384, out_features=1152, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.164)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
          (downsample): PatchMerging(
            (reduction): Linear(in_features=1536, out_features=768, bias=False)
            (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=768, out_features=2304, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=768, out_features=768, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.182)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=768, out_features=3072, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=3072, out_features=768, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=768, out_features=2304, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=768, out_features=768, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.200)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=768, out_features=3072, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=3072, out_features=768, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
      )
      (norm0): Identity()
      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (fpn): FPN(
      (fpn_inner2): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (fpn_layer2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (fpn_inner3): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (fpn_layer3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (fpn_inner4): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (fpn_layer4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (top_blocks): LastLevelP6P7(
        (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
      (drop_block): DropBlock2D()
    )
  )
  (language_backbone): Sequential(
    (body): BertEncoder(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
    )
  )
  (rpn): VLDyHeadModule(
    (head): VLDyHead(
      (dyhead_tower): Sequential(
        (0): DyConv(
          (DyConv): ModuleList(
            (0): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
            (1): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
            (2): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=2, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
          )
          (AttnConv): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
            (2): ReLU(inplace=True)
          )
          (h_sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
          (relu): DYReLU(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=256, out_features=64, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=64, out_features=1024, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (1): DyConv(
          (DyConv): ModuleList(
            (0): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
            (1): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
            (2): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=2, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
          )
          (AttnConv): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
            (2): ReLU(inplace=True)
          )
          (h_sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
          (relu): DYReLU(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=256, out_features=64, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=64, out_features=1024, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (2): DyConv(
          (DyConv): ModuleList(
            (0): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
            (1): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
            (2): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=2, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
          )
          (AttnConv): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
            (2): ReLU(inplace=True)
          )
          (h_sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
          (relu): DYReLU(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=256, out_features=64, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=64, out_features=1024, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (3): DyConv(
          (DyConv): ModuleList(
            (0): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
            (1): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
            (2): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=2, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
          )
          (AttnConv): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
            (2): ReLU(inplace=True)
          )
          (h_sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
          (relu): DYReLU(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=256, out_features=64, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=64, out_features=1024, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (4): DyConv(
          (DyConv): ModuleList(
            (0): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
            (1): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
            (2): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=2, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
          )
          (AttnConv): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
            (2): ReLU(inplace=True)
          )
          (h_sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
          (relu): DYReLU(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=256, out_features=64, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=64, out_features=1024, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (5): DyConv(
          (DyConv): ModuleList(
            (0): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
            (1): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
            (2): Conv3x3Norm(
              (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=2, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
              (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
            )
          )
          (AttnConv): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
            (2): ReLU(inplace=True)
          )
          (h_sigmoid): h_sigmoid(
            (relu): ReLU6(inplace=True)
          )
          (relu): DYReLU(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=256, out_features=64, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=64, out_features=1024, bias=True)
              (3): h_sigmoid(
                (relu): ReLU6(inplace=True)
              )
            )
          )
          (offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (cls_logits): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
      (bbox_pred): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (centerness): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (dot_product_projection_image): Identity()
      (dot_product_projection_text): Linear(in_features=768, out_features=256, bias=True)
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
    (loss_evaluator): ATSSLossComputation(
      (cls_loss_func): SigmoidFocalLoss(gamma=2.0, alpha=0.25)
      (centerness_loss_func): BCEWithLogitsLoss()
      (token_loss_func): TokenSigmoidFocalLoss(gamma=2.0, alpha=0.25)
    )
    (box_selector_train): ATSSPostProcessor()
    (box_selector_test): ATSSPostProcessor()
    (anchor_generator): AnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
)
